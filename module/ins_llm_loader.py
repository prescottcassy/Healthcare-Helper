# -*- coding: utf-8 -*-
"""Healthcare_helper_data.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uSsmezYm1P1FDKxEp_5EacnE74MEI7Xe

**Tools we will be Using**

â€¢	LangChain: Framework for building LLM-powered applications

â€¢	ChromaDB or FAISS: Vector store for embedding-based retrieval

â€¢	OpenAI GPT-4: For generation (via API or ChatGPT)

â€¢	Embedding Model: OpenAI embeddings or HuggingFace alternatives
"""

!pip install langchain chromadb openai tiktoken
# or use FAISS instead of ChromaDB
!pip install faiss-cpu
!pip install requests
# Install Tesseract OCR and Python wrapper
!apt-get update
!apt-get install -y tesseract-ocr
!pip install pytesseract
!apt-get install -y poppler-utils
!pip install pdf2image
!pip install -U langchain-community

# Imports
import os
import pandas as pd
import requests
from google.colab import userdata, files
from PIL import Image
from pdf2image import convert_from_path
import pytesseract
import requests
from google.colab import userdata, files
from PIL import Image
import pytesseract

from pdf2image import convert_from_path
from langchain.document_loaders import CSVLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA

# Set OpenAI API key
# os.environ["OPENAI_API_KEY"] = userdata.get("OPENAI_API_KEY")

# Load insurance dataset
# insurance_path = "/content/insurance.csv"
# insurance_df = pd.read_csv(insurance_path)
# insurance_loader = CSVLoader(file_path=insurance_path)
# insurance_docs = insurance_loader.load()

# Split into chunks
# splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=30)
# chunks = splitter.split_documents(insurance_docs)

# Embed and store in vector DB
# embedding = OpenAIEmbeddings()
# db = Chroma.from_documents(chunks, embedding)
# retriever = db.as_retriever(search_kwargs={"k": 3})

# Set up GPT model
# llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0)
# qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)

# Function to query FDA for drugs related to a symptom
def get_drugs_for_symptom(symptom):
    url = "https://api.fda.gov/drug/drugsfda.json"
    params = {"search": f"products.active_ingredient:{symptom}", "limit": 10}
    try:
        response = requests.get(url, params=params)
        data = response.json()
        if "results" in data:
            return [item["products"][0]["brand_name"].lower() for item in data["results"]]
        else:
            return []
    except:
        return []

# Function to look up insurance by name
# def lookup_insurance(name_input):
#     name_input = name_input.lower()
#     matches = insurance_df[
#         insurance_df["COMPANY NAME"].str.lower().str.contains(name_input) |
#         insurance_df["PLAN NAME"].str.lower().str.contains(name_input)
#     ]

#     if matches.empty:
#         print("No matching insurance plans found.")
#     else:
#         print("Matching Insurance Plans:")
#         print(matches[["COMPANY NAME", "PLAN NAME", "PRICE", "COVERAGE"]])

        # Optional: Ask GPT to summarize
        # summary_query = f"Summarize the insurance plans offered by '{name_input}' based on coverage and price."
        # summary = qa_chain.run(summary_query)
        # print("\n GPT Summary:")
        # print(summary)

# ðŸ§ª Try it out
# name_input = input("Enter insurance company or plan name: ")
# lookup_insurance(name_input)

# Upload insurance card
uploaded = files.upload()
for filename in uploaded:
    if filename.endswith(".pdf"):
        images = convert_from_path(filename)
        card_text = "\n".join([pytesseract.image_to_string(img) for img in images])
    else:
         img = Image.open(filename)
         card_text = pytesseract.image_to_string(img)

print("\n Extracted Insurance Info:")
print(card_text)

# ðŸ©º Get health concern from user
# symptom_input = input("\nEnter your health concern (e.g. diabetes, asthma): ").lower()
# drugs = get_drugs_for_symptom(symptom_input)

# Match insurance plans
# matches = insurance_df[insurance_df["COVERAGE"].str.lower().str.contains('|'.join(drugs))] if drugs else pd.DataFrame()

# if matches.empty:
#     print(" No matching plans found. Asking GPT for help...")
#     query = f"Based on insurance data, what is the best-priced plan for someone with '{symptom_input}'?"
#     response = qa_chain.run(query)
#     print("\n GPT Recommendation:")
#     print(response)
# else:
#     print("\n Matching Plans Based on Your Concern:")
#     print(matches[["COMPANY NAME", "PLAN NAME", "PRICE", "COVERAGE"]])
#     print(insurance_df.columns.tolist())